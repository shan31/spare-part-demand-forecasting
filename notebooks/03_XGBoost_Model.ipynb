{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# XGBoost Model for Spare Part Demand Forecasting\n",
                "\n",
                "This notebook implements XGBoost for short-term demand forecasting (1-14 days).\n",
                "\n",
                "## Objectives\n",
                "1. Load and prepare data with feature engineering\n",
                "2. Train XGBoost model\n",
                "3. Hyperparameter tuning\n",
                "4. Evaluate model performance\n",
                "5. Feature importance analysis\n",
                "6. Compare with Prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('Libraries loaded successfully!')\n",
                "print(f'XGBoost version: {xgb.__version__}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load daily aggregated demand\n",
                "df = pd.read_csv('../data/processed/daily_demand.csv', parse_dates=['date'])\n",
                "print(f'Loaded {len(df)} rows')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create date-based features\n",
                "df['day_of_week'] = df['date'].dt.dayofweek\n",
                "df['day_of_month'] = df['date'].dt.day\n",
                "df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
                "df['month'] = df['date'].dt.month\n",
                "df['quarter'] = df['date'].dt.quarter\n",
                "df['year'] = df['date'].dt.year\n",
                "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
                "df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
                "df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
                "\n",
                "print('Date features created!')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create lag features\n",
                "lags = [1, 7, 14, 30]\n",
                "for lag in lags:\n",
                "    df[f'lag_{lag}'] = df['demand_quantity'].shift(lag)\n",
                "\n",
                "print(f'Lag features created: {lags}')\n",
                "df.head(35)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create rolling features\n",
                "windows = [7, 14, 30]\n",
                "for window in windows:\n",
                "    df[f'rolling_mean_{window}'] = df['demand_quantity'].shift(1).rolling(window=window).mean()\n",
                "    df[f'rolling_std_{window}'] = df['demand_quantity'].shift(1).rolling(window=window).std()\n",
                "\n",
                "print(f'Rolling features created for windows: {windows}')\n",
                "df.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop rows with NaN values (from lag and rolling features)\n",
                "df_clean = df.dropna().copy()\n",
                "print(f'Rows after dropping NaN: {len(df_clean)} (dropped {len(df) - len(df_clean)})')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check all features\n",
                "print('Final features:')\n",
                "print(df_clean.columns.tolist())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define target and features\n",
                "target = 'demand_quantity'\n",
                "exclude_cols = ['date', 'demand_quantity', 'revenue']\n",
                "feature_cols = [col for col in df_clean.columns if col not in exclude_cols]\n",
                "\n",
                "print(f'Target: {target}')\n",
                "print(f'Features ({len(feature_cols)}): {feature_cols}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Time series split (no shuffling!)\n",
                "test_days = 30\n",
                "train_df = df_clean[:-test_days]\n",
                "test_df = df_clean[-test_days:]\n",
                "\n",
                "X_train = train_df[feature_cols]\n",
                "y_train = train_df[target]\n",
                "X_test = test_df[feature_cols]\n",
                "y_test = test_df[target]\n",
                "\n",
                "print(f'Training set: {X_train.shape}')\n",
                "print(f'Test set: {X_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train XGBoost Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize XGBoost model\n",
                "model = xgb.XGBRegressor(\n",
                "    n_estimators=100,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.1,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    objective='reg:squarederror'\n",
                ")\n",
                "\n",
                "print('XGBoost model initialized!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print('Training XGBoost model...')\n",
                "model.fit(\n",
                "    X_train, y_train,\n",
                "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
                "    verbose=False\n",
                ")\n",
                "print('Model trained successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
                "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print('='*50)\n",
                "print('XGBOOST MODEL EVALUATION METRICS')\n",
                "print('='*50)\n",
                "print(f'MAE  (Mean Absolute Error):     {mae:.2f}')\n",
                "print(f'RMSE (Root Mean Squared Error): {rmse:.2f}')\n",
                "print(f'MAPE (Mean Absolute % Error):   {mape:.2f}%')\n",
                "print(f'R2   (R-Squared):               {r2:.4f}')\n",
                "print('='*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize actual vs predicted\n",
                "results_df = pd.DataFrame({\n",
                "    'Date': test_df['date'].values,\n",
                "    'Actual': y_test.values,\n",
                "    'Predicted': y_pred\n",
                "})\n",
                "\n",
                "fig = go.Figure()\n",
                "fig.add_trace(go.Scatter(x=results_df['Date'], y=results_df['Actual'],\n",
                "                         mode='lines+markers', name='Actual', line=dict(color='blue')))\n",
                "fig.add_trace(go.Scatter(x=results_df['Date'], y=results_df['Predicted'],\n",
                "                         mode='lines+markers', name='Predicted', line=dict(color='orange')))\n",
                "\n",
                "fig.update_layout(title='XGBoost: Actual vs Predicted (Test Period)',\n",
                "                  xaxis_title='Date', yaxis_title='Demand')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature importance\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': feature_cols,\n",
                "    'Importance': model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "print('Top 10 Features:')\n",
                "importance_df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize feature importance\n",
                "fig = px.bar(importance_df.head(15), x='Importance', y='Feature', orientation='h',\n",
                "             title='XGBoost Feature Importance (Top 15)',\n",
                "             color='Importance', color_continuous_scale='Oranges')\n",
                "fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define parameter grid\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 150],\n",
                "    'max_depth': [4, 6, 8],\n",
                "    'learning_rate': [0.05, 0.1, 0.15]\n",
                "}\n",
                "\n",
                "# Time series cross-validation\n",
                "tscv = TimeSeriesSplit(n_splits=3)\n",
                "\n",
                "# Grid search\n",
                "print('Running hyperparameter tuning (this may take a few minutes)...')\n",
                "grid_search = GridSearchCV(\n",
                "    xgb.XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
                "    param_grid,\n",
                "    cv=tscv,\n",
                "    scoring='neg_mean_absolute_error',\n",
                "    n_jobs=-1,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "grid_search.fit(X_train, y_train)\n",
                "print('Tuning complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best parameters\n",
                "print('Best Parameters:')\n",
                "print(grid_search.best_params_)\n",
                "print(f'\\nBest CV Score (MAE): {-grid_search.best_score_:.2f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train final model with best parameters\n",
                "best_model = grid_search.best_estimator_\n",
                "\n",
                "# Evaluate on test set\n",
                "y_pred_best = best_model.predict(X_test)\n",
                "\n",
                "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
                "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
                "mape_best = np.mean(np.abs((y_test - y_pred_best) / y_test)) * 100\n",
                "\n",
                "print('='*50)\n",
                "print('TUNED XGBOOST MODEL METRICS')\n",
                "print('='*50)\n",
                "print(f'MAE:  {mae_best:.2f} (vs {mae:.2f} before tuning)')\n",
                "print(f'RMSE: {rmse_best:.2f} (vs {rmse:.2f} before tuning)')\n",
                "print(f'MAPE: {mape_best:.2f}% (vs {mape:.2f}% before tuning)')\n",
                "print('='*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Cross-Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform cross-validation on full dataset\n",
                "tscv = TimeSeriesSplit(n_splits=5)\n",
                "\n",
                "X_full = df_clean[feature_cols]\n",
                "y_full = df_clean[target]\n",
                "\n",
                "cv_scores = cross_val_score(best_model, X_full, y_full, cv=tscv, scoring='neg_mean_absolute_error')\n",
                "\n",
                "print('Cross-Validation Results (5-fold TimeSeriesSplit):')\n",
                "print(f'MAE Scores: {-cv_scores}')\n",
                "print(f'Mean MAE: {-cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the trained model\n",
                "import os\n",
                "os.makedirs('../models', exist_ok=True)\n",
                "\n",
                "model_data = {\n",
                "    'model': best_model,\n",
                "    'feature_names': feature_cols,\n",
                "    'params': grid_search.best_params_\n",
                "}\n",
                "\n",
                "model_path = '../models/xgboost_model.pkl'\n",
                "with open(model_path, 'wb') as f:\n",
                "    pickle.dump(model_data, f)\n",
                "\n",
                "print(f'Model saved to: {model_path}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save metrics for comparison\n",
                "metrics = {\n",
                "    'model': 'XGBoost',\n",
                "    'mae': mae_best,\n",
                "    'rmse': rmse_best,\n",
                "    'mape': mape_best,\n",
                "    'cv_mae_mean': -cv_scores.mean()\n",
                "}\n",
                "\n",
                "metrics_df = pd.DataFrame([metrics])\n",
                "metrics_df.to_csv('../models/xgboost_metrics.csv', index=False)\n",
                "print('Metrics saved!')\n",
                "metrics_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Compare with Prophet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Prophet metrics if available\n",
                "try:\n",
                "    prophet_metrics = pd.read_csv('../models/prophet_metrics.csv')\n",
                "    xgb_metrics = pd.DataFrame([metrics])\n",
                "    \n",
                "    comparison = pd.concat([prophet_metrics, xgb_metrics], ignore_index=True)\n",
                "    print('Model Comparison:')\n",
                "    print(comparison.to_string(index=False))\n",
                "    \n",
                "    # Determine winner\n",
                "    if comparison.loc[comparison['model'] == 'XGBoost', 'mae'].values[0] < comparison.loc[comparison['model'] == 'Prophet', 'mae'].values[0]:\n",
                "        print('\\n[WINNER] XGBoost has lower MAE!')\n",
                "    else:\n",
                "        print('\\n[WINNER] Prophet has lower MAE!')\n",
                "        \n",
                "except FileNotFoundError:\n",
                "    print('Prophet metrics not found. Run Prophet notebook first for comparison.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visual comparison\n",
                "try:\n",
                "    fig = go.Figure(data=[\n",
                "        go.Bar(name='Prophet', x=['MAE', 'RMSE', 'MAPE'], \n",
                "               y=[prophet_metrics['mae'].values[0], prophet_metrics['rmse'].values[0], prophet_metrics['mape'].values[0]],\n",
                "               marker_color='#3B82F6'),\n",
                "        go.Bar(name='XGBoost', x=['MAE', 'RMSE', 'MAPE'], \n",
                "               y=[mae_best, rmse_best, mape_best],\n",
                "               marker_color='#F97316')\n",
                "    ])\n",
                "    fig.update_layout(title='Model Comparison: Prophet vs XGBoost', barmode='group')\n",
                "    fig.show()\n",
                "except:\n",
                "    print('Could not create comparison chart.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "| Metric | Value |\n",
                "|--------|-------|\n",
                "| Model | XGBoost |\n",
                "| Training Period | ~670 days |\n",
                "| Test Period | 30 days |\n",
                "| Features | 20+ (lag, rolling, date features) |\n",
                "| MAE | See above |\n",
                "| RMSE | See above |\n",
                "| MAPE | See above |\n",
                "\n",
                "**Notes:**\n",
                "- XGBoost uses feature engineering (lags, rolling stats)\n",
                "- Hyperparameter tuning with GridSearchCV\n",
                "- Best for short-term forecasts (1-14 days)\n",
                "- Model saved for deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('XGBoost Model Training Complete!')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}